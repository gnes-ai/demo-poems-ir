!PipelineEncoder
components:
  - !PytorchTransformer
    parameters:
      model_dir: $TORCH_TRANSFORMERS_MODEL
      model_name: bert-base-uncased
  - !PoolingEncoder
    parameters:
      pooling_strategy: REDUCE_MEAN
      backend: torch
gnes_config:
  name: my_transformer  # a customized name
  is_trained: true  # indicate the model has been trained
  work_dir: /workspace
  batch_size: 128